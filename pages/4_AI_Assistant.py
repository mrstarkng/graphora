import streamlit as st
import pandas as pd
import plotly.express as px
from google import genai
from google.genai import types
import numpy as np
import os
import json

st.set_page_config(page_title="Tr·ª£ l√Ω AI", layout="wide")

st.title("ü§ñ Tr·ª£ l√Ω AI")
st.write("### üìå Ch·ªçn d·ªØ li·ªáu, tr·ª±c quan h√≥a v√† h·ªèi AI")

# --- Chart Generation Functions (Copied from ai.py) ---


def safe_get_column(df, column_name, dtype=None):
    """Safely get a column, checking existence and optionally type."""
    if column_name not in df.columns:
        st.error(f"L·ªói: C·ªôt '{column_name}' kh√¥ng t√¨m th·∫•y trong b·ªô d·ªØ li·ªáu.", icon="‚ö†Ô∏è")
        return None
    col = df[column_name]
    if dtype:
        if dtype == "numeric" and not pd.api.types.is_numeric_dtype(col):
            st.error(f"L·ªói: C·ªôt '{column_name}' kh√¥ng ph·∫£i l√† s·ªë.", icon="‚ö†Ô∏è")
            return None
        if (
            dtype == "categorical"
            and not pd.api.types.is_object_dtype(col)
            and not pd.api.types.is_categorical_dtype(col)
        ):
            st.warning(
                f"C·∫£nh b√°o: C·ªôt '{column_name}' c√≥ th·ªÉ kh√¥ng l√Ω t∆∞·ªüng cho ph√¢n t√≠ch danh m·ª•c.",
                icon="‚ö†Ô∏è",
            )
        if dtype == "datetime":
            if not pd.api.types.is_datetime64_any_dtype(col):
                try:
                    col = pd.to_datetime(col)
                except Exception:
                    st.error(
                        f"L·ªói: Kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi c·ªôt '{column_name}' sang ƒë·ªãnh d·∫°ng ng√†y gi·ªù.",
                        icon="‚ö†Ô∏è",
                    )
                    return None
    return col


def generate_histogram(df: pd.DataFrame, column_name: str, num_bins: int = 30):
    """Generates a histogram for a numeric column."""
    data_col = safe_get_column(df, column_name, dtype="numeric")
    if data_col is None:
        return None
    try:
        fig = px.histogram(
            df,
            x=column_name,
            nbins=int(num_bins),
            title=f"Ph√¢n ph·ªëi c·ªßa {column_name}",
            template="plotly_white",
        )
        fig.update_layout(bargap=0.1)
        return fig
    except Exception as e:
        st.error(f"L·ªói t·∫°o bi·ªÉu ƒë·ªì t·∫ßn su·∫•t cho {column_name}: {e}", icon="‚ö†Ô∏è")
        return None


def generate_bar_chart(df: pd.DataFrame, column_name: str, top_n: int = 10):
    """Generates a bar chart for a categorical column."""
    data_col = safe_get_column(df, column_name, dtype="categorical")
    if data_col is None:
        st.warning(
            f"C·ªôt '{column_name}' c√≥ th·ªÉ kh√¥ng ph·∫£i l√† danh m·ª•c. ƒêang th·ª≠ t·∫°o bi·ªÉu ƒë·ªì c·ªôt.",
            icon="‚ö†Ô∏è",
        )
    try:
        top_n = int(top_n)
        counts = df[column_name].value_counts().nlargest(top_n).reset_index()
        counts.columns = [column_name, "count"]
        fig = px.bar(
            counts,
            x=column_name,
            y="count",
            title=f"{top_n} Danh m·ª•c h√†ng ƒë·∫ßu trong {column_name}",
            template="plotly_white",
            text="count",
        )
        fig.update_traces(textposition="outside")
        fig.update_layout(xaxis_title=column_name, yaxis_title="S·ªë l∆∞·ª£ng")
        return fig
    except Exception as e:
        st.error(f"L·ªói t·∫°o bi·ªÉu ƒë·ªì c·ªôt cho {column_name}: {e}", icon="‚ö†Ô∏è")
        return None


def generate_pie_chart(df: pd.DataFrame, column_name: str, top_n: int = 5):
    """Generates a pie chart for a categorical column, grouping smaller slices."""
    data_col = safe_get_column(df, column_name, dtype="categorical")
    if data_col is None:
        st.warning(
            f"C·ªôt '{column_name}' c√≥ th·ªÉ kh√¥ng ph·∫£i l√† danh m·ª•c. ƒêang th·ª≠ t·∫°o bi·ªÉu ƒë·ªì tr√≤n.",
            icon="‚ö†Ô∏è",
        )
    try:
        top_n = int(top_n)
        counts = df[column_name].value_counts().reset_index()
        counts.columns = [column_name, "count"]

        if len(counts) > top_n:
            top_df = counts.nlargest(top_n - 1, "count")
            other_sum = counts.nsmallest(len(counts) - (top_n - 1), "count")[
                "count"
            ].sum()
            if other_sum > 0:
                other_row = pd.DataFrame({column_name: ["Kh√°c"], "count": [other_sum]})
                pie_df = pd.concat([top_df, other_row], ignore_index=True)
            else:
                pie_df = top_df
        else:
            pie_df = counts

        fig = px.pie(
            pie_df,
            names=column_name,
            values="count",
            title=f"T·ª∑ l·ªá {top_n} Danh m·ª•c h√†ng ƒë·∫ßu trong {column_name}",
            template="plotly_white",
        )
        fig.update_traces(textposition="inside", textinfo="percent+label")
        return fig
    except Exception as e:
        st.error(f"L·ªói t·∫°o bi·ªÉu ƒë·ªì tr√≤n cho {column_name}: {e}", icon="‚ö†Ô∏è")
        return None


def generate_line_chart(df: pd.DataFrame, x_column: str, y_column: str):
    """Generates a line chart for trends over time or sequence."""
    x_data = safe_get_column(df, x_column)
    y_data = safe_get_column(df, y_column, dtype="numeric")
    if x_data is None or y_data is None:
        return None
    try:
        df_line = df[[x_column, y_column]].copy()
        if not pd.api.types.is_numeric_dtype(
            df_line[x_column]
        ) and not pd.api.types.is_datetime64_any_dtype(df_line[x_column]):
            try:
                df_line[x_column] = pd.to_datetime(df_line[x_column])
                st.info(
                    f"ƒê√£ chuy·ªÉn ƒë·ªïi c·ªôt '{x_column}' sang ng√†y gi·ªù cho bi·ªÉu ƒë·ªì ƒë∆∞·ªùng."
                )
            except Exception:
                st.warning(
                    f"Kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi tr·ª•c X '{x_column}' sang Ng√†y/Gi·ªù. Gi·ªØ nguy√™n.",
                    icon="‚ö†Ô∏è",
                )
        df_line = df_line.sort_values(by=x_column).dropna(subset=[x_column, y_column])
        if not df_line.empty:
            fig = px.line(
                df_line,
                x=x_column,
                y=y_column,
                title=f"Xu h∆∞·ªõng c·ªßa {y_column} theo {x_column}",
                template="plotly_white",
                markers=True,
            )
            fig.update_layout(xaxis_title=x_column, yaxis_title=y_column)
            return fig
        else:
            st.warning(
                f"Kh√¥ng t√¨m th·∫•y ƒëi·ªÉm d·ªØ li·ªáu h·ª£p l·ªá cho Bi·ªÉu ƒë·ªì ƒë∆∞·ªùng ({y_column} vs {x_column}).",
                icon="‚ö†Ô∏è",
            )
            return None
    except Exception as e:
        st.error(f"L·ªói t·∫°o bi·ªÉu ƒë·ªì ƒë∆∞·ªùng ({y_column} vs {x_column}): {e}", icon="‚ö†Ô∏è")
        return None


def generate_scatter_plot(
    df: pd.DataFrame, x_column: str, y_column: str, color_column: str = None
):
    """Generates a scatter plot between two numeric columns, optionally colored by a third."""
    x_data = safe_get_column(df, x_column, dtype="numeric")
    y_data = safe_get_column(df, y_column, dtype="numeric")
    color_data = None
    if color_column and color_column != "None" and color_column.strip() != "":
        color_data = safe_get_column(df, color_column)
        if color_data is None:
            st.warning(
                f"C·ªôt m√†u '{color_column}' kh√¥ng t√¨m th·∫•y ho·∫∑c kh√¥ng h·ª£p l·ªá. Bi·ªÉu ƒë·ªì ph√¢n t√°n s·∫Ω kh√¥ng ƒë∆∞·ª£c t√¥ m√†u.",
                icon="‚ö†Ô∏è",
            )
            color_column = None
    else:
        color_column = None
    if x_data is None or y_data is None:
        return None
    try:
        plot_args = {
            "x": x_column,
            "y": y_column,
            "title": f"{y_column} vs {x_column}",
            "template": "plotly_white",
        }
        if color_column:
            plot_args["color"] = color_column
            plot_args["title"] += f" (T√¥ m√†u theo {color_column})"

        sample_size = min(2000, df.shape[0])
        df_sample = df.sample(sample_size) if df.shape[0] > 2000 else df

        fig = px.scatter(df_sample, **plot_args)
        return fig
    except Exception as e:
        st.error(f"L·ªói t·∫°o bi·ªÉu ƒë·ªì ph√¢n t√°n ({y_column} vs {x_column}): {e}", icon="‚ö†Ô∏è")
        return None


# --- Mapping function names to functions ---
AVAILABLE_FUNCTIONS = {
    "generate_histogram": generate_histogram,
    "generate_bar_chart": generate_bar_chart,
    "generate_pie_chart": generate_pie_chart,
    "generate_line_chart": generate_line_chart,
    "generate_scatter_plot": generate_scatter_plot,
}

# --- Define Tools for Gemini (Copied from ai.py) ---
tools = types.Tool(
    function_declarations=[
        types.FunctionDeclaration(
            name="generate_histogram",
            description="T·∫°o bi·ªÉu ƒë·ªì t·∫ßn su·∫•t cho m·ªôt c·ªôt s·ªë ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh ƒë·ªÉ hi·ªÉn th·ªã ph√¢n ph·ªëi c·ªßa n√≥.",
            parameters=types.Schema(
                type=types.Type.OBJECT,
                properties={
                    "column_name": types.Schema(
                        type=types.Type.STRING,
                        description="T√™n c·ªôt s·ªë.",
                    ),
                    "num_bins": types.Schema(
                        type=types.Type.INTEGER,
                        description="S·ªë l∆∞·ª£ng kho·∫£ng (m·∫∑c ƒë·ªãnh 30).",
                        default=30,
                    ),
                },
                required=["column_name"],
            ),
        ),
        types.FunctionDeclaration(
            name="generate_bar_chart",
            description="T·∫°o bi·ªÉu ƒë·ªì c·ªôt cho m·ªôt c·ªôt danh m·ª•c ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh ƒë·ªÉ hi·ªÉn th·ªã s·ªë l∆∞·ª£ng c√°c danh m·ª•c h√†ng ƒë·∫ßu.",
            parameters=types.Schema(
                type=types.Type.OBJECT,
                properties={
                    "column_name": types.Schema(
                        type=types.Type.STRING,
                        description="T√™n c·ªôt danh m·ª•c.",
                    ),
                    "top_n": types.Schema(
                        type=types.Type.INTEGER,
                        description="S·ªë l∆∞·ª£ng danh m·ª•c h√†ng ƒë·∫ßu c·∫ßn hi·ªÉn th·ªã (m·∫∑c ƒë·ªãnh 10).",
                        default=10,
                    ),
                },
                required=["column_name"],
            ),
        ),
        types.FunctionDeclaration(
            name="generate_pie_chart",
            description="T·∫°o bi·ªÉu ƒë·ªì tr√≤n cho m·ªôt c·ªôt danh m·ª•c ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh ƒë·ªÉ hi·ªÉn th·ªã t·ª∑ l·ªá c·ªßa c√°c danh m·ª•c h√†ng ƒë·∫ßu.",
            parameters=types.Schema(
                type=types.Type.OBJECT,
                properties={
                    "column_name": types.Schema(
                        type=types.Type.STRING,
                        description="T√™n c·ªôt danh m·ª•c.",
                    ),
                    "top_n": types.Schema(
                        type=types.Type.INTEGER,
                        description="S·ªë l∆∞·ª£ng l√°t c·∫Øt (nh√≥m c√°c m·ª•c kh√°c, m·∫∑c ƒë·ªãnh 5).",
                        default=5,
                    ),
                },
                required=["column_name"],
            ),
        ),
        types.FunctionDeclaration(
            name="generate_line_chart",
            description="T·∫°o bi·ªÉu ƒë·ªì ƒë∆∞·ªùng ƒë·ªÉ hi·ªÉn th·ªã xu h∆∞·ªõng c·ªßa m·ªôt c·ªôt s·ªë theo m·ªôt c·ªôt s·ªë ho·∫∑c ng√†y gi·ªù kh√°c (tr·ª•c X).",
            parameters=types.Schema(
                type=types.Type.OBJECT,
                properties={
                    "x_column": types.Schema(
                        type=types.Type.STRING,
                        description="C·ªôt cho tr·ª•c X (th·ªùi gian ho·∫∑c chu·ªói).",
                    ),
                    "y_column": types.Schema(
                        type=types.Type.STRING,
                        description="C·ªôt s·ªë cho tr·ª•c Y.",
                    ),
                },
                required=["x_column", "y_column"],
            ),
        ),
        types.FunctionDeclaration(
            name="generate_scatter_plot",
            description="T·∫°o bi·ªÉu ƒë·ªì ph√¢n t√°n ƒë·ªÉ hi·ªÉn th·ªã m·ªëi quan h·ªá gi·ªØa hai c·ªôt s·ªë. T√πy ch·ªçn t√¥ m√†u c√°c ƒëi·ªÉm theo c·ªôt th·ª© ba.",
            parameters=types.Schema(
                type=types.Type.OBJECT,
                properties={
                    "x_column": types.Schema(
                        type=types.Type.STRING,
                        description="C·ªôt s·ªë cho tr·ª•c X.",
                    ),
                    "y_column": types.Schema(
                        type=types.Type.STRING,
                        description="C·ªôt s·ªë cho tr·ª•c Y.",
                    ),
                    "color_column": types.Schema(
                        type=types.Type.STRING,
                        description="C·ªôt danh m·ª•c ho·∫∑c s·ªë t√πy ch·ªçn ƒë·ªÉ t√¥ m√†u c√°c ƒëi·ªÉm. S·ª≠ d·ª•ng 'None' ho·∫∑c b·ªè qua n·∫øu kh√¥ng t√¥ m√†u.",
                        nullable=True,
                        default=None,
                    ),
                },
                required=["x_column", "y_column"],
            ),
        ),
    ]
)


# --- Configure Gemini AI ---
client = None
config = None
try:
    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        st.error("üö® Bi·∫øn m√¥i tr∆∞·ªùng GEMINI_API_KEY ch∆∞a ƒë∆∞·ª£c ƒë·∫∑t!")
        st.stop()
    client = genai.Client(api_key=api_key)
except Exception as e:
    st.error(f"L·ªói c·∫•u h√¨nh Gemini AI: {e}")
    st.warning(
        "Vui l√≤ng ƒë·∫£m b·∫£o kh√≥a API ƒë∆∞·ª£c ƒë·∫∑t ch√≠nh x√°c v√† b·∫°n c√≥ c√°c g√≥i c·∫ßn thi·∫øt."
    )
    client = None

# Initialize session memory
if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []
if "selected_df_name" not in st.session_state:
    st.session_state["selected_df_name"] = None
if "selected_df" not in st.session_state:
    st.session_state["selected_df"] = None

# --- Load DataFrames ---
DATA_DIR = "data"
try:
    dfs = {
        "ƒê·ªãa ph∆∞∆°ng": {
            "Ti·ªÉu h·ªçc": pd.read_csv(os.path.join(DATA_DIR, "dia-phuong/tieu-hoc.csv")),
            "Trung h·ªçc c∆° s·ªü": pd.read_csv(
                os.path.join(DATA_DIR, "dia-phuong/THCS.csv")
            ),
            "Trung h·ªçc ph·ªï th√¥ng": pd.read_csv(
                os.path.join(DATA_DIR, "dia-phuong/THPT.csv")
            ),
        },
        "M·∫´u gi√°o": {
            "ƒê·ªãa ph∆∞∆°ng": pd.read_csv(os.path.join(DATA_DIR, "mau-giao/MG.csv")),
            "T·ªïng quan M·∫´u gi√°o": pd.read_csv(
                os.path.join(DATA_DIR, "mau-giao/tong-quan-MG.csv")
            ),
        },
        "T·ªïng quan": {
            "Ch·ªâ s·ªë ph√°t tri·ªÉn": pd.read_csv(
                os.path.join(DATA_DIR, "tong-quan/chi-so-phat-trien.csv")
            ),
            "T·ªïng quan": pd.read_csv(os.path.join(DATA_DIR, "tong-quan/tong-quan.csv")),
            "T·ªïng quan (t·∫•t c·∫£)": pd.read_csv(
                os.path.join(DATA_DIR, "tong-quan/tong-quan-all.csv")
            ),
        },
    }
    flat_dfs = {}
    for category, sub_dfs in dfs.items():
        for name, df in sub_dfs.items():
            flat_dfs[f"{category} - {name}"] = df

except FileNotFoundError as e:
    st.error(
        f"üö® L·ªói t·∫£i t·ªáp d·ªØ li·ªáu: {e}. Vui l√≤ng ƒë·∫£m b·∫£o c√°c t·ªáp d·ªØ li·ªáu c√≥ m·∫∑t t·∫°i ƒë∆∞·ªùng d·∫´n d·ª± ki·∫øn b·∫Øt ƒë·∫ßu t·ª´ '{DATA_DIR}'."
    )
    st.stop()
except Exception as e:
    st.error(f"üö® ƒê√£ x·∫£y ra l·ªói kh√¥ng mong mu·ªën khi t·∫£i d·ªØ li·ªáu: {e}")
    st.stop()


# --- DataFrame Selection ---
st.sidebar.header("Ch·ªçn D·ªØ li·ªáu ƒë·ªÉ Ph√¢n t√≠ch")
available_df_names = list(flat_dfs.keys())
selected_df_key = st.sidebar.selectbox(
    "Ch·ªçn m·ªôt b·ªô d·ªØ li·ªáu:",
    options=available_df_names,
    index=(
        available_df_names.index(st.session_state["selected_df_name"])
        if st.session_state["selected_df_name"] in available_df_names
        else 0
    ),
    key="df_selector",
)

if selected_df_key != st.session_state["selected_df_name"]:
    st.session_state["selected_df_name"] = selected_df_key
    st.session_state["selected_df"] = flat_dfs[selected_df_key]
    st.session_state["chat_history"] = []
    st.rerun()

df_to_analyze = st.session_state.get("selected_df")
analysis_target_name = st.session_state.get("selected_df_name")

if df_to_analyze is not None and client and analysis_target_name:
    st.header(f"ƒêang ph√¢n t√≠ch: {analysis_target_name}")
    st.success(
        f"S·∫µn s√†ng ph√¢n t√≠ch: **{analysis_target_name}** ({df_to_analyze.shape[0]} h√†ng, {df_to_analyze.shape[1]} c·ªôt)"
    )

    try:
        numeric_columns = df_to_analyze.select_dtypes(
            include=np.number
        ).columns.tolist()
        categorical_columns = df_to_analyze.select_dtypes(
            include=["object", "category"]
        ).columns.tolist()
        datetime_columns = df_to_analyze.select_dtypes(
            include="datetime"
        ).columns.tolist()
        potential_dt_cols = []
        for col in df_to_analyze.select_dtypes(include="object").columns:
            if (
                df_to_analyze[col]
                .astype(str)
                .str.match(r"\d{4}-\d{2}-\d{2}|\d{1,2}/\d{1,2}/\d{4}")
                .any()
            ):
                potential_dt_cols.append(col)

        column_info_prompt = f"""
C√°c c·ªôt c√≥ s·∫µn trong b·ªô d·ªØ li·ªáu '{analysis_target_name}':
- C·ªôt s·ªë: {numeric_columns if numeric_columns else 'Kh√¥ng c√≥'}
- C·ªôt danh m·ª•c: {categorical_columns if categorical_columns else 'Kh√¥ng c√≥'}
- C·ªôt ng√†y gi·ªù (ƒê√£ ph√°t hi·ªán): {datetime_columns if datetime_columns else 'Kh√¥ng c√≥'}
- C·ªôt c√≥ th·ªÉ l√† ng√†y gi·ªù (ki·ªÉu object): {potential_dt_cols if potential_dt_cols else 'Kh√¥ng c√≥'}

S·ª≠ d·ª•ng c√°c c√¥ng c·ª• ƒë∆∞·ª£c cung c·∫•p ƒë·ªÉ t·∫°o tr·ª±c quan h√≥a d·ª±a tr√™n c√°c c·ªôt n√†y khi ƒë∆∞·ª£c y√™u c·∫ßu.
Y√™u c·∫ßu l√†m r√µ n·∫øu y√™u c·∫ßu kh√¥ng r√µ r√†ng v·ªÅ t√™n ho·∫∑c lo·∫°i c·ªôt.
Cung c·∫•p c√¢u tr·∫£ l·ªùi b·∫±ng vƒÉn b·∫£n cho c√°c c√¢u h·ªèi chung v·ªÅ d·ªØ li·ªáu.
Khi s·ª≠ d·ª•ng generate_line_chart, h√£y th·ª≠ chuy·ªÉn ƒë·ªïi c√°c c·ªôt ng√†y gi·ªù ti·ªÅm nƒÉng n·∫øu ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh l√†m tr·ª•c x.
Khi s·ª≠ d·ª•ng generate_scatter_plot, c·ªôt m√†u (color_column) c√≥ th·ªÉ l√† s·ªë ho·∫∑c danh m·ª•c.
"""
    except Exception as e:
        st.warning(f"Kh√¥ng th·ªÉ t·ª± ƒë·ªông x√°c ƒë·ªãnh t·∫•t c·∫£ c√°c lo·∫°i c·ªôt: {e}")
        column_info_prompt = f"Vi·ªác ph√°t hi·ªán lo·∫°i c·ªôt c√≥ th·ªÉ ch∆∞a ho√†n ch·ªânh. C√°c c·ªôt c√≥ s·∫µn trong '{analysis_target_name}': {df_to_analyze.columns.tolist()}\nS·ª≠ d·ª•ng c√°c c√¥ng c·ª• d·ª±a tr√™n y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng v√† t√™n c·ªôt."

    with st.expander("üìä T·ªïng quan nhanh v·ªÅ d·ªØ li·ªáu", expanded=False):
        st.markdown("#### Th√¥ng tin c∆° b·∫£n & D·ªØ li·ªáu m·∫´u")
        col_info, col_sample = st.columns([1, 2])
        with col_info:
            st.metric("T·ªïng s·ªë h√†ng", df_to_analyze.shape[0])
            st.metric("T·ªïng s·ªë c·ªôt", df_to_analyze.shape[1])
            st.text("Lo·∫°i c·ªôt:")
            try:
                st.json(
                    df_to_analyze.dtypes.apply(lambda x: str(x)).to_dict(),
                    expanded=False,
                )
            except Exception as json_e:
                st.text(f"Kh√¥ng th·ªÉ hi·ªÉn th·ªã lo·∫°i c·ªôt d∆∞·ªõi d·∫°ng JSON: {json_e}")
                st.text(df_to_analyze.dtypes)

        with col_sample:
            st.text("D·ªØ li·ªáu m·∫´u (5 h√†ng ƒë·∫ßu ti√™n):")
            st.dataframe(df_to_analyze.head())

        st.markdown("#### T√≥m t·∫Øt s·ªë li·ªáu")
        if numeric_columns:
            st.dataframe(df_to_analyze[numeric_columns].describe())
        else:
            st.caption("Kh√¥ng t√¨m th·∫•y c·ªôt s·ªë n√†o cho th·ªëng k√™ t√≥m t·∫Øt.")

    st.write("---")
    st.subheader("üí¨ H·ªèi AI v·ªÅ d·ªØ li·ªáu n√†y")
    st.caption(
        f"V√≠ d·ª•: 'Hi·ªÉn th·ªã ph√¢n ph·ªëi c·ªßa [t√™n c·ªôt s·ªë]', 'So s√°nh [c·ªôt s·ªë 1] v√† [c·ªôt s·ªë 2]', 'C√°c danh m·ª•c ph·ªï bi·∫øn nh·∫•t trong [t√™n c·ªôt danh m·ª•c] l√† g√¨?' s·ª≠ d·ª•ng c√°c c·ªôt t·ª´ '{analysis_target_name}'."
    )

    SYSTEM_PROMPT = f"""
ƒê√¢y l√† m√¥ t·∫£ ·ª©ng d·ª•ng c·ªßa t√¥i:
"Graphora l√† m·ªôt n·ªÅn t·∫£ng tr·ª±c quan h√≥a d·ªØ li·ªáu gi√°o d·ª•c ƒë∆∞·ª£c thi·∫øt k·∫ø nh·∫±m ph·ª•c v·ª• cho m·ª•c ti√™u **ph√¢n t√≠ch v√† ƒë√°nh gi√° to√†n di·ªán t√¨nh h√¨nh gi√°o d·ª•c t·∫°i Vi·ªát Nam"    
B·∫°n l√† m·ªôt tr·ª£ l√Ω AI cho ·ª©ng d·ª•ng n√†y, chuy√™n ph√¢n t√≠ch d·ªØ li·ªáu CSV ƒë∆∞·ª£c cung c·∫•p c√≥ t√™n '{analysis_target_name}'.
M·ª•c ti√™u c·ªßa b·∫°n l√† gi√∫p ng∆∞·ªùi d√πng hi·ªÉu d·ªØ li·ªáu c·ªßa h·ªç b·∫±ng c√°ch tr·∫£ l·ªùi c√°c c√¢u h·ªèi v√† t·∫°o c√°c tr·ª±c quan h√≥a li√™n quan b·∫±ng c√°c c√¥ng c·ª• c√≥ s·∫µn.
**H√£y tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát.**

B·ªëi c·∫£nh d·ªØ li·ªáu cho '{analysis_target_name}':
{column_info_prompt}
5 h√†ng ƒë·∫ßu ti√™n c·ªßa d·ªØ li·ªáu:
{df_to_analyze.head().to_string()}

H∆∞·ªõng d·∫´n:
- Ph√¢n t√≠ch y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng m·ªôt c√°ch c·∫©n th·∫≠n, xem x√©t b·ªëi c·∫£nh c·ªßa b·ªô d·ªØ li·ªáu '{analysis_target_name}'.
- N·∫øu y√™u c·∫ßu y√™u c·∫ßu m·ªôt tr·ª±c quan h√≥a ph√π h·ª£p v·ªõi m·ªôt trong c√°c c√¥ng c·ª• c·ªßa b·∫°n (bi·ªÉu ƒë·ªì t·∫ßn su·∫•t, bi·ªÉu ƒë·ªì c·ªôt, bi·ªÉu ƒë·ªì tr√≤n, bi·ªÉu ƒë·ªì ƒë∆∞·ªùng, bi·ªÉu ƒë·ªì ph√¢n t√°n), h√£y s·ª≠ d·ª•ng l·ªánh g·ªçi h√†m c√¥ng c·ª• th√≠ch h·ª£p v·ªõi t√™n c·ªôt ch√≠nh x√°c d·ª±a tr√™n B·ªëi c·∫£nh d·ªØ li·ªáu ƒë∆∞·ª£c cung c·∫•p ·ªü tr√™n.
- ƒê·∫£m b·∫£o b·∫°n s·ª≠ d·ª•ng t√™n c·ªôt CH√çNH X√ÅC nh∆∞ ƒë∆∞·ª£c li·ªát k√™ trong B·ªëi c·∫£nh d·ªØ li·ªáu. Kh√¥ng t·ª± t·∫°o t√™n c·ªôt.
- N·∫øu y√™u c·∫ßu kh√¥ng r√µ r√†ng, y√™u c·∫ßu m·ªôt c·ªôt kh√¥ng t·ªìn t·∫°i ho·∫∑c s·ª≠ d·ª•ng m·ªôt c·ªôt sai lo·∫°i cho bi·ªÉu ƒë·ªì ƒë∆∞·ª£c y√™u c·∫ßu, h√£y y√™u c·∫ßu ng∆∞·ªùi d√πng l√†m r√µ. Cung c·∫•p c√°c t√πy ch·ªçn c·ª• th·ªÉ n·∫øu c√≥ th·ªÉ.
- ƒê·ªëi v·ªõi c√°c c√¢u h·ªèi chung v·ªÅ d·ªØ li·ªáu (v√≠ d·ª•: 'Gi√° tr·ªã trung b√¨nh trong [c·ªôt] l√† g√¨?', 'C√≥ bao nhi√™u gi√° tr·ªã duy nh·∫•t trong [c·ªôt]?'), h√£y cung c·∫•p c√¢u tr·∫£ l·ªùi tr·ª±c ti·∫øp b·∫±ng vƒÉn b·∫£n d·ª±a tr√™n b·ªëi c·∫£nh d·ªØ li·ªáu n·∫øu c√≥ th·ªÉ, ho·∫∑c gi·∫£i th√≠ch n·∫øu th√¥ng tin kh√¥ng c√≥ s·∫µn.
- Gi·ªØ c√°c c√¢u tr·∫£ l·ªùi vƒÉn b·∫£n c·ªßa b·∫°n ng·∫Øn g·ªçn v√† t·∫≠p trung v√†o truy v·∫•n c·ªßa ng∆∞·ªùi d√πng.
- N·∫øu ng∆∞·ªùi d√πng y√™u c·∫ßu b·∫°n v·∫Ω m·ªôt bi·ªÉu ƒë·ªì ng·∫´u nhi√™n, h√£y suy lu·∫≠n v·ªÅ d·ªØ li·ªáu v√† t·ª± ƒë·ªông g·ªçi h√†m th√≠ch h·ª£p ƒë·ªÉ t·∫°o bi·ªÉu ƒë·ªì m√† kh√¥ng c·∫ßn h·ªèi th√™m ng∆∞·ªùi d√πng.
- Khi ƒë·ªÅ xu·∫•t, h√£y t·∫≠p trung v√†o vi·ªác ƒë·ªÅ xu·∫•t m·ª•c ƒë√≠ch c·ªßa bi·ªÉu ƒë·ªì thay v√¨ chi ti·∫øt c·ªßa n√≥.
- **Lu√¥n tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát.**
"""

    user_query = st.chat_input(
        f"H·ªèi v·ªÅ '{analysis_target_name}'...", key="ai_query_input_final"
    )

    if user_query:
        st.session_state.chat_history.append(
            types.Content(role="user", parts=[types.Part(text=user_query)])
        )
        with st.chat_message("user"):
            st.markdown(user_query)

        api_history = []
        for msg in st.session_state.chat_history:
            if isinstance(msg, dict):
                role = msg.get("role")
                parts_data = msg.get("parts")
                if role and parts_data:
                    if isinstance(parts_data, list) and isinstance(parts_data[0], str):
                        api_history.append(
                            types.Content(
                                role=role, parts=[types.Part(text=parts_data[0])]
                            )
                        )
            elif isinstance(msg, types.Content):
                api_history.append(msg)

        try:
            with st.spinner("ü§ñ AI ƒëang suy nghƒ©..."):
                response = client.models.generate_content(
                    model="gemini-2.0-flash",
                    contents=api_history,
                    config=types.GenerateContentConfig(
                        tools=[tools],
                        system_instruction=SYSTEM_PROMPT,
                    ),
                )

                response_content = response.candidates[0].content
                st.session_state.chat_history.append(response_content)

                with st.chat_message("model"):
                    response_part = response_content.parts[0]

                    if response_part.function_call:
                        function_call = response_part.function_call
                        function_name = function_call.name
                        function_args = {
                            key: value for key, value in function_call.args.items()
                        }

                        st.markdown(
                            f"_AI mu·ªën ch·∫°y `{function_name}` v·ªõi c√°c tham s·ªë: `{function_args}`_"
                        )

                        if function_name in AVAILABLE_FUNCTIONS:
                            chart_function = AVAILABLE_FUNCTIONS[function_name]
                            function_args_with_df = {
                                "df": df_to_analyze,
                                **function_args,
                            }

                            fig = chart_function(**function_args_with_df)

                            if fig:
                                st.plotly_chart(fig, use_container_width=True)
                                st.markdown(
                                    f"OK. ƒê√¢y l√† `{function_name.replace('_', ' ')}` b·∫°n y√™u c·∫ßu cho '{analysis_target_name}'."
                                )
                            else:
                                error_message = f"Kh√¥ng th·ªÉ t·∫°o bi·ªÉu ƒë·ªì ƒë∆∞·ª£c y√™u c·∫ßu (`{function_name}`). Vui l√≤ng ki·ªÉm tra t√™n c·ªôt v√† lo·∫°i ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p trong l·ªói ·ªü tr√™n ho·∫∑c th·ª≠ m·ªôt y√™u c·∫ßu kh√°c."
                                st.error(error_message)
                                st.session_state.chat_history.append(
                                    types.Content(
                                        role="model",
                                        parts=[types.Part(text=error_message)],
                                    )
                                )

                        else:
                            error_message = f"L·ªói: AI y√™u c·∫ßu m·ªôt h√†m kh√¥ng x√°c ƒë·ªãnh '{function_name}'."
                            st.error(error_message)
                            st.session_state.chat_history.append(
                                types.Content(
                                    role="model", parts=[types.Part(text=error_message)]
                                )
                            )

                    elif response_part.text:
                        response_text = response_part.text
                        st.markdown(response_text)
                    else:
                        st.warning("AI tr·∫£ v·ªÅ m·ªôt ph·∫£n h·ªìi tr·ªëng.")

        except Exception as e:
            st.error(f"ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh t∆∞∆°ng t√°c v·ªõi AI: {e}", icon="üî•")
            st.session_state.chat_history.append(
                types.Content(
                    role="model",
                    parts=[types.Part(text=f"L·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {e}")],
                )
            )
            st.rerun()

    st.write("---")
    if st.session_state.get("chat_history"):
        if st.button("X√≥a l·ªãch s·ª≠ tr√≤ chuy·ªán", key="ai_clear_history_final"):
            st.session_state["chat_history"] = []
            st.rerun()

elif not client:
    st.warning("Tr·ª£ l√Ω AI y√™u c·∫ßu c·∫•u h√¨nh API v√† kh√≥a API h·ª£p l·ªá.")
elif df_to_analyze is None:
    st.info("‚òùÔ∏è Ch·ªçn m·ªôt b·ªô d·ªØ li·ªáu t·ª´ thanh b√™n ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
