from time import sleep
import streamlit as st
import pandas as pd
import plotly.express as px
from google import genai
from google.genai import types
import numpy as np
import os
import json
import base64  # th√™m

st.set_page_config(page_title="Tr·ª£ l√Ω AI", layout="wide")

st.title("ü§ñ Tr·ª£ l√Ω AI")
st.write("### üìå H·ªèi AI v·ªÅ d·ªØ li·ªáu gi√°o d·ª•c Vi·ªát Nam")


# --- Filter Helper Function ---
def apply_filters(df: pd.DataFrame, filters_json: str) -> tuple[pd.DataFrame, str]:
    """
    Applies filters specified in a JSON string to the DataFrame.
    Returns the filtered DataFrame and a string describing the applied filters.
    """
    if (
        not filters_json
        or filters_json.strip() == "{}"
        or filters_json.lower() == "none"
    ):
        return df, ""  # Return original df and empty filter string

    try:
        filters = json.loads(filters_json)
        if not isinstance(filters, dict):
            st.warning(
                "B·ªô l·ªçc JSON kh√¥ng h·ª£p l·ªá (kh√¥ng ph·∫£i l√† dictionary). B·ªè qua b·ªô l·ªçc.",
                icon="‚ö†Ô∏è",
            )
            return df, ""

        filtered_df = df.copy()
        applied_filters_list = []
        for column, criteria in filters.items():
            if column not in filtered_df.columns:
                st.warning(
                    f"C·ªôt l·ªçc '{column}' kh√¥ng t·ªìn t·∫°i trong b·ªô d·ªØ li·ªáu. B·ªè qua b·ªô l·ªçc n√†y.",
                    icon="‚ö†Ô∏è",
                )
                continue

            try:
                original_count = len(filtered_df)
                filter_desc = ""
                if isinstance(criteria, list):
                    filtered_df = filtered_df[filtered_df[column].isin(criteria)]
                    filter_desc = f"{column} trong {criteria}"
                else:  # Assume single value equality
                    filtered_df = filtered_df[filtered_df[column] == criteria]
                    filter_desc = f"{column} == '{criteria}'"

                if len(filtered_df) < original_count:
                    applied_filters_list.append(filter_desc)

                if filtered_df.empty:
                    st.warning(
                        f"Kh√¥ng c√≤n d·ªØ li·ªáu sau khi √°p d·ª•ng b·ªô l·ªçc: {filter_desc}. Ki·ªÉm tra l·∫°i ti√™u ch√≠ l·ªçc.",
                        icon="‚ö†Ô∏è",
                    )
                    break  # Stop applying further filters if data is empty

            except Exception as filter_e:
                st.warning(
                    f"L·ªói khi √°p d·ª•ng b·ªô l·ªçc cho c·ªôt '{column}' v·ªõi ti√™u ch√≠ '{criteria}': {filter_e}. B·ªè qua b·ªô l·ªçc n√†y.",
                    icon="‚ö†Ô∏è",
                )

        applied_filters_str = ""
        if applied_filters_list:
            applied_filters_str = " (L·ªçc theo: " + "; ".join(applied_filters_list) + ")"
            st.info(f"ƒê√£ √°p d·ª•ng b·ªô l·ªçc: {'; '.join(applied_filters_list)}.")

        return filtered_df, applied_filters_str

    except json.JSONDecodeError:
        st.warning(
            f"Chu·ªói JSON b·ªô l·ªçc kh√¥ng h·ª£p l·ªá: '{filters_json}'. B·ªè qua b·ªô l·ªçc.",
            icon="‚ö†Ô∏è",
        )
        return df, ""
    except Exception as e:
        st.error(f"L·ªói kh√¥ng mong mu·ªën khi √°p d·ª•ng b·ªô l·ªçc: {e}", icon="‚ö†Ô∏è")
        return df, ""


# --- Chart Generation Functions (Modified) ---


def safe_get_column(df, column_name, dtype=None):
    """Safely get a column, checking existence and optionally type."""
    if column_name not in df.columns:
        st.error(f"L·ªói: C·ªôt '{column_name}' kh√¥ng t√¨m th·∫•y trong b·ªô d·ªØ li·ªáu.", icon="‚ö†Ô∏è")
        return None
    col = df[column_name]
    if dtype:
        if dtype == "numeric" and not pd.api.types.is_numeric_dtype(col):
            st.error(f"L·ªói: C·ªôt '{column_name}' kh√¥ng ph·∫£i l√† s·ªë.", icon="‚ö†Ô∏è")
            return None
        if (
            dtype == "categorical"
            and not pd.api.types.is_object_dtype(col)
            and not pd.api.types.is_categorical_dtype(col)
        ):
            st.warning(
                f"C·∫£nh b√°o: C·ªôt '{column_name}' c√≥ th·ªÉ kh√¥ng l√Ω t∆∞·ªüng cho ph√¢n t√≠ch danh m·ª•c.",
                icon="‚ö†Ô∏è",
            )
        if dtype == "datetime":
            if not pd.api.types.is_datetime64_any_dtype(col):
                try:
                    col = pd.to_datetime(col)
                except Exception:
                    st.error(
                        f"L·ªói: Kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi c·ªôt '{column_name}' sang ƒë·ªãnh d·∫°ng ng√†y gi·ªù.",
                        icon="‚ö†Ô∏è",
                    )
                    return None
    return col


def generate_histogram(
    df: pd.DataFrame, column_name: str, num_bins: int = 30, filters_json: str = None
):
    """Generates a histogram for a numeric column after applying filters."""
    df_filtered, filter_desc = apply_filters(df, filters_json)
    if df_filtered.empty:
        st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì sau khi l·ªçc.")
        return None

    data_col = safe_get_column(df_filtered, column_name, dtype="numeric")
    if data_col is None:
        return None
    try:
        fig = px.histogram(
            df_filtered,
            x=column_name,
            nbins=int(num_bins),
            title=f"Ph√¢n ph·ªëi c·ªßa {column_name}{filter_desc}",
            template="plotly_white",
        )
        fig.update_layout(bargap=0.1)
        return fig
    except Exception as e:
        st.error(f"L·ªói t·∫°o bi·ªÉu ƒë·ªì t·∫ßn su·∫•t cho {column_name}: {e}", icon="‚ö†Ô∏è")
        return None


def generate_bar_chart(
    df: pd.DataFrame, column_name: str, top_n: int = 10, filters_json: str = None
):
    """Generates a bar chart for a categorical column after applying filters."""
    df_filtered, filter_desc = apply_filters(df, filters_json)
    if df_filtered.empty:
        st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì sau khi l·ªçc.")
        return None

    data_col = safe_get_column(df_filtered, column_name, dtype="categorical")
    if data_col is None:
        st.warning(
            f"C·ªôt '{column_name}' c√≥ th·ªÉ kh√¥ng ph·∫£i l√† danh m·ª•c. ƒêang th·ª≠ t·∫°o bi·ªÉu ƒë·ªì c·ªôt.",
            icon="‚ö†Ô∏è",
        )
    try:
        top_n = int(top_n)
        counts = df_filtered[column_name].value_counts().nlargest(top_n).reset_index()
        counts.columns = [column_name, "count"]
        fig = px.bar(
            counts,
            x=column_name,
            y="count",
            title=f"{top_n} Danh m·ª•c h√†ng ƒë·∫ßu trong {column_name}{filter_desc}",
            template="plotly_white",
            text="count",
        )
        fig.update_traces(textposition="outside")
        fig.update_layout(xaxis_title=column_name, yaxis_title="S·ªë l∆∞·ª£ng")
        return fig
    except Exception as e:
        st.error(f"L·ªói t·∫°o bi·ªÉu ƒë·ªì c·ªôt cho {column_name}: {e}", icon="‚ö†Ô∏è")
        return None


def generate_pie_chart(
    df: pd.DataFrame, column_name: str, top_n: int = 5, filters_json: str = None
):
    """Generates a pie chart for a categorical column after applying filters."""
    df_filtered, filter_desc = apply_filters(df, filters_json)
    if df_filtered.empty:
        st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì sau khi l·ªçc.")
        return None

    data_col = safe_get_column(df_filtered, column_name, dtype="categorical")
    if data_col is None:
        st.warning(
            f"C·ªôt '{column_name}' c√≥ th·ªÉ kh√¥ng ph·∫£i l√† danh m·ª•c. ƒêang th·ª≠ t·∫°o bi·ªÉu ƒë·ªì tr√≤n.",
            icon="‚ö†Ô∏è",
        )
    try:
        top_n = int(top_n)
        counts = df_filtered[column_name].value_counts().reset_index()
        counts.columns = [column_name, "count"]

        if len(counts) > top_n:
            top_df = counts.nlargest(top_n - 1, "count")
            other_sum = counts.nsmallest(len(counts) - (top_n - 1), "count")[
                "count"
            ].sum()
            if other_sum > 0:
                other_row = pd.DataFrame({column_name: ["Kh√°c"], "count": [other_sum]})
                pie_df = pd.concat([top_df, other_row], ignore_index=True)
            else:
                pie_df = top_df
        else:
            pie_df = counts

        fig = px.pie(
            pie_df,
            names=column_name,
            values="count",
            title=f"T·ª∑ l·ªá {top_n} Danh m·ª•c h√†ng ƒë·∫ßu trong {column_name}{filter_desc}",
            template="plotly_white",
        )
        fig.update_traces(textposition="inside", textinfo="percent+label")
        return fig
    except Exception as e:
        st.error(f"L·ªói t·∫°o bi·ªÉu ƒë·ªì tr√≤n cho {column_name}: {e}", icon="‚ö†Ô∏è")
        return None


def generate_line_chart(
    df: pd.DataFrame,
    x_column: str,
    y_column: str,
    aggregation: str = "sum",
    group_by_column: str = None,
    filters_json: str = None,
):
    """
    Generates a line chart after applying filters. Handles aggregation/grouping.
    """
    df_filtered, filter_desc = apply_filters(df, filters_json)
    if df_filtered.empty:
        st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì sau khi l·ªçc.")
        return None

    x_data = safe_get_column(df_filtered, x_column)
    y_data = safe_get_column(df_filtered, y_column, dtype="numeric")
    group_data = None
    if group_by_column and group_by_column != "None" and group_by_column.strip() != "":
        group_data = safe_get_column(df_filtered, group_by_column)
        if group_data is None:
            st.warning(
                f"C·ªôt nh√≥m '{group_by_column}' kh√¥ng h·ª£p l·ªá. S·∫Ω b·ªè qua vi·ªác nh√≥m.",
                icon="‚ö†Ô∏è",
            )
            group_by_column = None  # Reset if invalid
    else:
        group_by_column = None  # Ensure it's None if empty or "None"

    if x_data is None or y_data is None:
        return None

    try:
        cols_to_use = [x_column, y_column]
        if group_by_column:
            cols_to_use.append(group_by_column)

        df_line = df_filtered[cols_to_use].copy()

        if not pd.api.types.is_numeric_dtype(
            df_line[x_column]
        ) and not pd.api.types.is_datetime64_any_dtype(df_line[x_column]):
            try:
                df_line[x_column] = pd.to_datetime(df_line[x_column])
                st.info(
                    f"ƒê√£ chuy·ªÉn ƒë·ªïi c·ªôt '{x_column}' sang ng√†y gi·ªù cho bi·ªÉu ƒë·ªì ƒë∆∞·ªùng."
                )
            except Exception:
                st.warning(
                    f"Kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi tr·ª•c X '{x_column}' sang Ng√†y/Gi·ªù. Gi·ªØ nguy√™n.",
                    icon="‚ö†Ô∏è",
                )

        df_line = df_line.dropna(subset=[x_column, y_column])

        plot_title = f"Xu h∆∞·ªõng c·ªßa {y_column} theo {x_column}"
        plot_args = {
            "x": x_column,
            "y": y_column,
            "template": "plotly_white",
            "markers": True,
        }

        if group_by_column:
            df_line = df_line.sort_values(by=[group_by_column, x_column])
            plot_args["color"] = group_by_column
            plot_title += f" (Nh√≥m theo {group_by_column})"
            plot_data = df_line
        else:
            if df_line[x_column].duplicated().any():
                valid_aggregations = {
                    "sum": "T·ªïng",
                    "mean": "Trung b√¨nh",
                    "median": "Trung v·ªã",
                }
                agg_func = aggregation.lower() if aggregation else "sum"
                if agg_func not in valid_aggregations:
                    st.warning(
                        f"Ph∆∞∆°ng th·ª©c t·ªïng h·ª£p '{aggregation}' kh√¥ng h·ª£p l·ªá. S·ª≠ d·ª•ng 'sum'.",
                        icon="‚ö†Ô∏è",
                    )
                    agg_func = "sum"

                agg_label = valid_aggregations[agg_func]
                st.info(
                    f"Tr·ª•c X ('{x_column}') c√≥ gi√° tr·ªã tr√πng l·∫∑p. ƒêang t·ªïng h·ª£p '{y_column}' theo '{agg_label}'."
                )
                df_agg = df_line.groupby(x_column, as_index=False).agg(
                    {y_column: agg_func}
                )
                df_agg = df_agg.sort_values(by=x_column)
                plot_title = f"Xu h∆∞·ªõng {agg_label} c·ªßa {y_column} theo {x_column}"
                plot_data = df_agg
            else:
                df_line = df_line.sort_values(by=x_column)
                plot_data = df_line

        if not plot_data.empty:
            plot_args["title"] = plot_title + filter_desc
            fig = px.line(plot_data, **plot_args)
            fig.update_layout(xaxis_title=x_column, yaxis_title=y_column)
            return fig
        else:
            st.warning(
                f"Kh√¥ng t√¨m th·∫•y ƒëi·ªÉm d·ªØ li·ªáu h·ª£p l·ªá cho Bi·ªÉu ƒë·ªì ƒë∆∞·ªùng ({y_column} vs {x_column}).",
                icon="‚ö†Ô∏è",
            )
            return None

    except Exception as e:
        st.error(f"L·ªói t·∫°o bi·ªÉu ƒë·ªì ƒë∆∞·ªùng ({y_column} vs {x_column}): {e}", icon="‚ö†Ô∏è")
        return None


def generate_scatter_plot(
    df: pd.DataFrame,
    x_column: str,
    y_column: str,
    color_column: str = None,
    filters_json: str = None,
):
    """Generates a scatter plot after applying filters."""
    df_filtered, filter_desc = apply_filters(df, filters_json)
    if df_filtered.empty:
        st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì sau khi l·ªçc.")
        return None

    x_data = safe_get_column(df_filtered, x_column, dtype="numeric")
    y_data = safe_get_column(df_filtered, y_column, dtype="numeric")
    color_data = None
    if color_column and color_column != "None" and color_column.strip() != "":
        color_data = safe_get_column(df_filtered, color_column)
        if color_data is None:
            st.warning(
                f"C·ªôt m√†u '{color_column}' kh√¥ng t√¨m th·∫•y ho·∫∑c kh√¥ng h·ª£p l·ªá. Bi·ªÉu ƒë·ªì ph√¢n t√°n s·∫Ω kh√¥ng ƒë∆∞·ª£c t√¥ m√†u.",
                icon="‚ö†Ô∏è",
            )
            color_column = None
    else:
        color_column = None
    if x_data is None or y_data is None:
        return None
    try:
        plot_args = {
            "x": x_column,
            "y": y_column,
            "title": f"{y_column} vs {x_column}{filter_desc}",
            "template": "plotly_white",
        }
        if color_column:
            plot_args["color"] = color_column
            plot_args["title"] += f" (T√¥ m√†u theo {color_column})"

        sample_size = min(2000, df_filtered.shape[0])
        df_sample = (
            df_filtered.sample(sample_size)
            if df_filtered.shape[0] > 2000
            else df_filtered
        )

        fig = px.scatter(df_sample, **plot_args)
        return fig
    except Exception as e:
        st.error(f"L·ªói t·∫°o bi·ªÉu ƒë·ªì ph√¢n t√°n ({y_column} vs {x_column}): {e}", icon="‚ö†Ô∏è")
        return None


# --- Mapping function names to functions ---
AVAILABLE_FUNCTIONS = {
    "generate_histogram": generate_histogram,
    "generate_bar_chart": generate_bar_chart,
    "generate_pie_chart": generate_pie_chart,
    "generate_line_chart": generate_line_chart,
    "generate_scatter_plot": generate_scatter_plot,
}

# --- Define Tools for Gemini (Add filters_json parameter) ---
tools = types.Tool(
    function_declarations=[
        types.FunctionDeclaration(
            name="generate_histogram",
            description="T·∫°o bi·ªÉu ƒë·ªì t·∫ßn su·∫•t cho m·ªôt c·ªôt s·ªë ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh trong m·ªôt b·ªô d·ªØ li·ªáu c·ª• th·ªÉ, c√≥ th·ªÉ l·ªçc tr∆∞·ªõc.",
            parameters=types.Schema(
                type=types.Type.OBJECT,
                properties={
                    "dataframe_name": types.Schema(
                        type=types.Type.STRING,
                        description="T√™n c·ªßa b·ªô d·ªØ li·ªáu c·∫ßn s·ª≠ d·ª•ng (v√≠ d·ª•: 'ƒê·ªãa ph∆∞∆°ng - Ti·ªÉu h·ªçc').",
                    ),
                    "column_name": types.Schema(
                        type=types.Type.STRING,
                        description="T√™n c·ªôt s·ªë.",
                    ),
                    "num_bins": types.Schema(
                        type=types.Type.INTEGER,
                        description="S·ªë l∆∞·ª£ng kho·∫£ng (m·∫∑c ƒë·ªãnh 30).",
                        default=30,
                    ),
                    "filters_json": types.Schema(
                        type=types.Type.STRING,
                        description='Chu·ªói JSON t√πy ch·ªçn ƒë·ªÉ l·ªçc d·ªØ li·ªáu tr∆∞·ªõc khi v·∫Ω. V√≠ d·ª•: \'{"ƒê·ªãa ph∆∞∆°ng": "H√† N·ªôi", "NƒÉm": [2020, 2021]}\'.',
                        nullable=True,
                        default=None,
                    ),
                },
                required=["dataframe_name", "column_name"],
            ),
        ),
        types.FunctionDeclaration(
            name="generate_bar_chart",
            description="T·∫°o bi·ªÉu ƒë·ªì c·ªôt cho m·ªôt c·ªôt danh m·ª•c ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh trong m·ªôt b·ªô d·ªØ li·ªáu c·ª• th·ªÉ, c√≥ th·ªÉ l·ªçc tr∆∞·ªõc.",
            parameters=types.Schema(
                type=types.Type.OBJECT,
                properties={
                    "dataframe_name": types.Schema(
                        type=types.Type.STRING,
                        description="T√™n c·ªßa b·ªô d·ªØ li·ªáu c·∫ßn s·ª≠ d·ª•ng.",
                    ),
                    "column_name": types.Schema(
                        type=types.Type.STRING,
                        description="T√™n c·ªôt danh m·ª•c.",
                    ),
                    "top_n": types.Schema(
                        type=types.Type.INTEGER,
                        description="S·ªë l∆∞·ª£ng danh m·ª•c h√†ng ƒë·∫ßu c·∫ßn hi·ªÉn th·ªã (m·∫∑c ƒë·ªãnh 10).",
                        default=10,
                    ),
                    "filters_json": types.Schema(
                        type=types.Type.STRING,
                        description='Chu·ªói JSON t√πy ch·ªçn ƒë·ªÉ l·ªçc d·ªØ li·ªáu tr∆∞·ªõc khi v·∫Ω. V√≠ d·ª•: \'{"Lo·∫°i tr∆∞·ªùng": "C√¥ng l·∫≠p"}\'.',
                        nullable=True,
                        default=None,
                    ),
                },
                required=["dataframe_name", "column_name"],
            ),
        ),
        types.FunctionDeclaration(
            name="generate_pie_chart",
            description="T·∫°o bi·ªÉu ƒë·ªì tr√≤n cho m·ªôt c·ªôt danh m·ª•c ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh trong m·ªôt b·ªô d·ªØ li·ªáu c·ª• th·ªÉ, c√≥ th·ªÉ l·ªçc tr∆∞·ªõc.",
            parameters=types.Schema(
                type=types.Type.OBJECT,
                properties={
                    "dataframe_name": types.Schema(
                        type=types.Type.STRING,
                        description="T√™n c·ªßa b·ªô d·ªØ li·ªáu c·∫ßn s·ª≠ d·ª•ng.",
                    ),
                    "column_name": types.Schema(
                        type=types.Type.STRING,
                        description="T√™n c·ªôt danh m·ª•c.",
                    ),
                    "top_n": types.Schema(
                        type=types.Type.INTEGER,
                        description="S·ªë l∆∞·ª£ng l√°t c·∫Øt (nh√≥m c√°c m·ª•c kh√°c, m·∫∑c ƒë·ªãnh 5).",
                        default=5,
                    ),
                    "filters_json": types.Schema(
                        type=types.Type.STRING,
                        description="Chu·ªói JSON t√πy ch·ªçn ƒë·ªÉ l·ªçc d·ªØ li·ªáu tr∆∞·ªõc khi v·∫Ω. V√≠ d·ª•: '{\"NƒÉm\": 2022}'.",
                        nullable=True,
                        default=None,
                    ),
                },
                required=["dataframe_name", "column_name"],
            ),
        ),
        types.FunctionDeclaration(
            name="generate_line_chart",
            description="T·∫°o bi·ªÉu ƒë·ªì ƒë∆∞·ªùng ƒë·ªÉ hi·ªÉn th·ªã xu h∆∞·ªõng, c√≥ th·ªÉ l·ªçc tr∆∞·ªõc. X·ª≠ l√Ω t·ªïng h·ª£p/nh√≥m n·∫øu c·∫ßn.",
            parameters=types.Schema(
                type=types.Type.OBJECT,
                properties={
                    "dataframe_name": types.Schema(
                        type=types.Type.STRING,
                        description="T√™n c·ªßa b·ªô d·ªØ li·ªáu c·∫ßn s·ª≠ d·ª•ng.",
                    ),
                    "x_column": types.Schema(
                        type=types.Type.STRING,
                        description="C·ªôt cho tr·ª•c X (th·ªùi gian ho·∫∑c chu·ªói).",
                    ),
                    "y_column": types.Schema(
                        type=types.Type.STRING,
                        description="C·ªôt s·ªë cho tr·ª•c Y.",
                    ),
                    "aggregation": types.Schema(
                        type=types.Type.STRING,
                        description="Ph∆∞∆°ng th·ª©c t·ªïng h·ª£p Y n·∫øu X tr√πng l·∫∑p (v√≠ d·ª•: 'sum', 'mean', 'median'). M·∫∑c ƒë·ªãnh l√† 'sum'. B·ªè qua n·∫øu group_by_column ƒë∆∞·ª£c s·ª≠ d·ª•ng.",
                        nullable=True,
                        default="sum",
                    ),
                    "group_by_column": types.Schema(
                        type=types.Type.STRING,
                        description="C·ªôt danh m·ª•c t√πy ch·ªçn ƒë·ªÉ nh√≥m d·ªØ li·ªáu v√† v·∫Ω nhi·ªÅu ƒë∆∞·ªùng ri√™ng bi·ªát.",
                        nullable=True,
                        default=None,
                    ),
                    "filters_json": types.Schema(
                        type=types.Type.STRING,
                        description='Chu·ªói JSON t√πy ch·ªçn ƒë·ªÉ l·ªçc d·ªØ li·ªáu tr∆∞·ªõc khi v·∫Ω. V√≠ d·ª•: \'{"ƒê·ªãa ph∆∞∆°ng": ["H√† N·ªôi", "TP. H·ªì Ch√≠ Minh"]}\'.',
                        nullable=True,
                        default=None,
                    ),
                },
                required=["dataframe_name", "x_column", "y_column"],
            ),
        ),
        types.FunctionDeclaration(
            name="generate_scatter_plot",
            description="T·∫°o bi·ªÉu ƒë·ªì ph√¢n t√°n ƒë·ªÉ hi·ªÉn th·ªã m·ªëi quan h·ªá gi·ªØa hai c·ªôt s·ªë, c√≥ th·ªÉ l·ªçc tr∆∞·ªõc.",
            parameters=types.Schema(
                type=types.Type.OBJECT,
                properties={
                    "dataframe_name": types.Schema(
                        type=types.Type.STRING,
                        description="T√™n c·ªßa b·ªô d·ªØ li·ªáu c·∫ßn s·ª≠ d·ª•ng.",
                    ),
                    "x_column": types.Schema(
                        type=types.Type.STRING,
                        description="C·ªôt s·ªë cho tr·ª•c X.",
                    ),
                    "y_column": types.Schema(
                        type=types.Type.STRING,
                        description="C·ªôt s·ªë cho tr·ª•c Y.",
                    ),
                    "color_column": types.Schema(
                        type=types.Type.STRING,
                        description="C·ªôt danh m·ª•c ho·∫∑c s·ªë t√πy ch·ªçn ƒë·ªÉ t√¥ m√†u c√°c ƒëi·ªÉm.",
                        nullable=True,
                        default=None,
                    ),
                    "filters_json": types.Schema(
                        type=types.Type.STRING,
                        description="Chu·ªói JSON t√πy ch·ªçn ƒë·ªÉ l·ªçc d·ªØ li·ªáu tr∆∞·ªõc khi v·∫Ω. V√≠ d·ª•: '{\"NƒÉm\": 2021}'.",
                        nullable=True,
                        default=None,
                    ),
                },
                required=["dataframe_name", "x_column", "y_column"],
            ),
        ),
    ]
)


# --- Configure Gemini AI ---
client = None
config = None
try:
    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        st.error("üö® Bi·∫øn m√¥i tr∆∞·ªùng GEMINI_API_KEY ch∆∞a ƒë∆∞·ª£c ƒë·∫∑t!")
        st.stop()
    client = genai.Client(api_key=api_key)
except Exception as e:
    st.error(f"L·ªói c·∫•u h√¨nh Gemini AI: {e}")
    st.warning(
        "Vui l√≤ng ƒë·∫£m b·∫£o kh√≥a API ƒë∆∞·ª£c ƒë·∫∑t ch√≠nh x√°c v√† b·∫°n c√≥ c√°c g√≥i c·∫ßn thi·∫øt."
    )
    client = None

# Initialize session memory
if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []

# --- Load DataFrames ---
DATA_DIR = "data"
flat_dfs = {}
datasets_overview = "T·ªïng quan v·ªÅ c√°c b·ªô d·ªØ li·ªáu c√≥ s·∫µn:\n\n"

# --- Descriptions for each dataset ---
dataset_descriptions = {
    "ƒê·ªãa ph∆∞∆°ng - Ti·ªÉu h·ªçc": "D·ªØ li·ªáu chi ti·∫øt v·ªÅ gi√°o d·ª•c ti·ªÉu h·ªçc theo t·ª´ng ƒë·ªãa ph∆∞∆°ng (t·ªânh/th√†nh ph·ªë).",
    "ƒê·ªãa ph∆∞∆°ng - Trung h·ªçc c∆° s·ªü": "D·ªØ li·ªáu chi ti·∫øt v·ªÅ gi√°o d·ª•c trung h·ªçc c∆° s·ªü theo t·ª´ng ƒë·ªãa ph∆∞∆°ng (t·ªânh/th√†nh ph·ªë).",
    "ƒê·ªãa ph∆∞∆°ng - Trung h·ªçc ph·ªï th√¥ng": "D·ªØ li·ªáu chi ti·∫øt v·ªÅ gi√°o d·ª•c trung h·ªçc ph·ªï th√¥ng theo t·ª´ng ƒë·ªãa ph∆∞∆°ng (t·ªânh/th√†nh ph·ªë).",
    "M·∫´u gi√°o - ƒê·ªãa ph∆∞∆°ng": "D·ªØ li·ªáu chi ti·∫øt v·ªÅ gi√°o d·ª•c m·∫´u gi√°o theo t·ª´ng ƒë·ªãa ph∆∞∆°ng (t·ªânh/th√†nh ph·ªë).",
    "M·∫´u gi√°o - T·ªïng quan M·∫´u gi√°o": "D·ªØ li·ªáu t·ªïng quan chung v·ªÅ t√¨nh h√¨nh gi√°o d·ª•c m·∫´u gi√°o tr√™n c·∫£ n∆∞·ªõc.",
    "T·ªïng quan - Ch·ªâ s·ªë ph√°t tri·ªÉn": "C√°c ch·ªâ s·ªë ph√°t tri·ªÉn gi√°o d·ª•c t·ªïng h·ª£p qua c√°c nƒÉm.",
    "T·ªïng quan - T·ªïng quan": "D·ªØ li·ªáu t·ªïng quan chung v·ªÅ gi√°o d·ª•c Vi·ªát Nam qua c√°c nƒÉm (c√≥ th·ªÉ bao g·ªìm nhi·ªÅu c·∫•p h·ªçc).",
    "T·ªïng quan - T·ªïng quan (t·∫•t c·∫£)": "B·ªô d·ªØ li·ªáu t·ªïng h·ª£p nh·∫•t, ch·ª©a th√¥ng tin t·ªïng quan v·ªÅ t·∫•t c·∫£ c√°c c·∫•p h·ªçc qua c√°c nƒÉm.",
}

try:
    dfs = {
        "ƒê·ªãa ph∆∞∆°ng": {
            "Ti·ªÉu h·ªçc": pd.read_csv(os.path.join(DATA_DIR, "dia-phuong/tieu-hoc.csv")),
            "Trung h·ªçc c∆° s·ªü": pd.read_csv(
                os.path.join(DATA_DIR, "dia-phuong/THCS.csv")
            ),
            "Trung h·ªçc ph·ªï th√¥ng": pd.read_csv(
                os.path.join(DATA_DIR, "dia-phuong/THPT.csv")
            ),
        },
        "M·∫´u gi√°o": {
            "ƒê·ªãa ph∆∞∆°ng": pd.read_csv(os.path.join(DATA_DIR, "mau-giao/MG.csv")),
            "T·ªïng quan M·∫´u gi√°o": pd.read_csv(
                os.path.join(DATA_DIR, "mau-giao/tong-quan-MG.csv")
            ),
        },
        "T·ªïng quan": {
            "Ch·ªâ s·ªë ph√°t tri·ªÉn": pd.read_csv(
                os.path.join(DATA_DIR, "tong-quan/chi-so-phat-trien.csv")
            ),
            "T·ªïng quan": pd.read_csv(os.path.join(DATA_DIR, "tong-quan/tong-quan.csv")),
            "T·ªïng quan (t·∫•t c·∫£)": pd.read_csv(
                os.path.join(DATA_DIR, "tong-quan/tong-quan-all.csv")
            ),
        },
    }
    for category, sub_dfs in dfs.items():
        for name, df in sub_dfs.items():
            full_name = f"{category} - {name}"
            flat_dfs[full_name] = df
            description = dataset_descriptions.get(full_name, "Kh√¥ng c√≥ m√¥ t·∫£.")
            # Get column types
            try:
                col_types = df.dtypes.apply(lambda x: str(x)).to_dict()
                col_types_str = "\n".join(
                    [f"    '{k}': {v}" for k, v in col_types.items()]
                )
            except Exception:
                col_types_str = "Kh√¥ng th·ªÉ l·∫•y ki·ªÉu d·ªØ li·ªáu c·ªôt."
            # Get first 5 rows
            try:
                f5r = df.head().to_string()
            except Exception:
                f5r = "Kh√¥ng th·ªÉ l·∫•y 5 h√†ng ƒë·∫ßu ti√™n."

            datasets_overview += f"- T√™n: '{full_name}'\n"
            datasets_overview += f"  M√¥ t·∫£: {description}\n"
            datasets_overview += f"  C·ªôt v√† Ki·ªÉu d·ªØ li·ªáu:\n{col_types_str}\n"
            datasets_overview += f"  5 h√†ng ƒë·∫ßu ti√™n (f5r):\n{f5r}\n\n"

except FileNotFoundError as e:
    st.error(
        f"üö® L·ªói t·∫£i t·ªáp d·ªØ li·ªáu: {e}. Vui l√≤ng ƒë·∫£m b·∫£o c√°c t·ªáp d·ªØ li·ªáu c√≥ m·∫∑t t·∫°i ƒë∆∞·ªùng d·∫´n d·ª± ki·∫øn b·∫Øt ƒë·∫ßu t·ª´ '{DATA_DIR}'."
    )
    st.stop()
except Exception as e:
    st.error(f"üö® ƒê√£ x·∫£y ra l·ªói kh√¥ng mong mu·ªën khi t·∫£i d·ªØ li·ªáu: {e}")
    st.stop()

# --- Chart Analysis System Prompt ---
CHART_ANALYSIS_PROMPT = """
B·∫°n l√† m·ªôt tr·ª£ l√Ω AI chuy√™n ph√¢n t√≠ch bi·ªÉu ƒë·ªì. D∆∞·ªõi ƒë√¢y l√† th√¥ng tin bi·ªÉu ƒë·ªì:
- H√†m ƒë√£ g·ªçi: {function_name}
- Tham s·ªë: {function_args}
B·∫°n s·∫Ω nh·∫≠n bi·ªÉu ƒë·ªì d∆∞·ªõi d·∫°ng h√¨nh ·∫£nh PNG base64.
H√£y ph√¢n t√≠ch bi·ªÉu ƒë·ªì n√†y, n√™u ra c√°c xu h∆∞·ªõng, b·∫•t th∆∞·ªùng, v√† g·ª£i √Ω √Ω nghƒ©a c·ªßa n√≥.
**Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát.**

- Bi·ªÉu ƒë·ªì ƒë∆∞·ª£c sinh = ai v·ªõi system prompt nh∆∞ sau, b·∫°n h√£y tham kh·∫£o ƒë·ªÉ hi·ªÉu h∆°n v·ªÅ dataset:
```
{system_prompt}
```
"""

# --- Main AI Interaction Area ---
if client and flat_dfs:
    st.success(f"S·∫µn s√†ng nh·∫≠n c√¢u h·ªèi v·ªÅ {len(flat_dfs)} b·ªô d·ªØ li·ªáu gi√°o d·ª•c.")

    st.write("---")
    st.subheader("üí¨ H·ªèi AI v·ªÅ d·ªØ li·ªáu")
    st.caption(
        "V√≠ d·ª•: 'T·∫°o bi·ªÉu ƒë·ªì t·∫ßn su·∫•t cho c·ªôt [t√™n c·ªôt] trong d·ªØ li·ªáu [t√™n b·ªô d·ªØ li·ªáu]', 'So s√°nh [c·ªôt 1] v√† [c·ªôt 2] t·ª´ [t√™n b·ªô d·ªØ li·ªáu]', 'D·ªØ li·ªáu n√†o n√≥i v·ªÅ ch·ªâ s·ªë ph√°t tri·ªÉn?'"
    )

    # --- List of Provinces ---
    provinces = [
        "An Giang",
        "B√† R·ªãa - V≈©ng T√†u",
        "B·∫Øc Giang",
        "B·∫Øc K·∫°n",
        "B·∫°c Li√™u",
        "B·∫Øc Ninh",
        "B·∫øn Tre",
        "B√¨nh ƒê·ªãnh",
        "B√¨nh D∆∞∆°ng",
        "B√¨nh Ph∆∞·ªõc",
        "B√¨nh Thu·∫≠n",
        "C√† Mau",
        "C·∫ßn Th∆°",
        "Cao B·∫±ng",
        "ƒê√† N·∫µng",
        "ƒê·∫Øk L·∫Øk",
        "ƒê·∫Øk N√¥ng",
        "ƒêi·ªán Bi√™n",
        "ƒê·ªìng Nai",
        "ƒê·ªìng Th√°p",
        "Gia Lai",
        "H√† Giang",
        "H√† Nam",
        "H√† N·ªôi",
        "H√† Tƒ©nh",
        "H·∫£i D∆∞∆°ng",
        "H·∫£i Ph√≤ng",
        "H·∫≠u Giang",
        "H√≤a B√¨nh",
        "H∆∞ng Y√™n",
        "Kh√°nh H√≤a",
        "Ki√™n Giang",
        "Kon Tum",
        "Lai Ch√¢u",
        "L√¢m ƒê·ªìng",
        "L·∫°ng S∆°n",
        "L√†o Cai",
        "Long An",
        "Nam ƒê·ªãnh",
        "Ngh·ªá An",
        "Ninh B√¨nh",
        "Ninh Thu·∫≠n",
        "Ph√∫ Th·ªç",
        "Ph√∫ Y√™n",
        "Qu·∫£ng B√¨nh",
        "Qu·∫£ng Nam",
        "Qu·∫£ng Ng√£i",
        "Qu·∫£ng Ninh",
        "Qu·∫£ng Tr·ªã",
        "S√≥c TrƒÉng",
        "S∆°n La",
        "T√¢y Ninh",
        "Th√°i B√¨nh",
        "Th√°i Nguy√™n",
        "Thanh H√≥a",
        "Th·ª´a Thi√™n Hu·∫ø",
        "Ti·ªÅn Giang",
        "Tr√† Vinh",
        "Tuy√™n Quang",
        "Vƒ©nh Long",
        "Vƒ©nh Ph√∫c",
        "Y√™n B√°i",
        "TP.H·ªì Ch√≠ Minh",
    ]
    provinces_list_str = (
        "Danh s√°ch c√°c gi√° tr·ªã 'ƒê·ªãa ph∆∞∆°ng' c√≥ th·ªÉ c√≥ (t·ªânh/th√†nh ph·ªë):\n"
        + ", ".join([f"'{p}'" for p in provinces])
        + "\n"
    )
    # --- End List of Provinces ---

    SYSTEM_PROMPT = f"""
ƒê√¢y l√† m√¥ t·∫£ ·ª©ng d·ª•ng c·ªßa t√¥i:
"Graphora l√† m·ªôt n·ªÅn t·∫£ng tr·ª±c quan h√≥a d·ªØ li·ªáu gi√°o d·ª•c ƒë∆∞·ª£c thi·∫øt k·∫ø nh·∫±m ph·ª•c v·ª• cho m·ª•c ti√™u **ph√¢n t√≠ch v√† ƒë√°nh gi√° to√†n di·ªán t√¨nh h√¨nh gi√°o d·ª•c t·∫°i Vi·ªát Nam"    
B·∫°n l√† m·ªôt tr·ª£ l√Ω AI cho ·ª©ng d·ª•ng n√†y, chuy√™n ph√¢n t√≠ch c√°c b·ªô d·ªØ li·ªáu CSV ƒë∆∞·ª£c cung c·∫•p v·ªÅ gi√°o d·ª•c Vi·ªát Nam.
M·ª•c ti√™u c·ªßa b·∫°n l√† gi√∫p ng∆∞·ªùi d√πng hi·ªÉu d·ªØ li·ªáu c·ªßa h·ªç b·∫±ng c√°ch tr·∫£ l·ªùi c√°c c√¢u h·ªèi v√† t·∫°o c√°c tr·ª±c quan h√≥a li√™n quan b·∫±ng c√°c c√¥ng c·ª• c√≥ s·∫µn.
**H√£y tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát.**

{datasets_overview}
{provinces_list_str}
H∆∞·ªõng d·∫´n:
- Ph√¢n t√≠ch y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng m·ªôt c√°ch c·∫©n th·∫≠n.
- **X√°c ƒë·ªãnh b·ªô d·ªØ li·ªáu (dataframe) ph√π h·ª£p nh·∫•t** t·ª´ danh s√°ch tr√™n d·ª±a tr√™n c√¢u h·ªèi, m√¥ t·∫£, danh s√°ch c·ªôt, ki·ªÉu d·ªØ li·ªáu v√† d·ªØ li·ªáu m·∫´u (f5r) c·ªßa t·ª´ng b·ªô d·ªØ li·ªáu. N·∫øu kh√¥ng r√µ r√†ng, h√£y h·ªèi ng∆∞·ªùi d√πng mu·ªën s·ª≠ d·ª•ng b·ªô d·ªØ li·ªáu n√†o.
- **L·ªçc d·ªØ li·ªáu (Filtering):** N·∫øu ng∆∞·ªùi d√πng y√™u c·∫ßu ph√¢n t√≠ch ho·∫∑c tr·ª±c quan h√≥a ch·ªâ m·ªôt ph·∫ßn d·ªØ li·ªáu (v√≠ d·ª•: 'ch·ªâ ·ªü H√† N·ªôi', 'cho nƒÉm 2022', 'ch·ªâ c√°c tr∆∞·ªùng c√¥ng l·∫≠p'), h√£y s·ª≠ d·ª•ng tham s·ªë `filters_json`. Tham s·ªë n√†y nh·∫≠n m·ªôt chu·ªói JSON.
    - ƒê·ªãnh d·∫°ng JSON: `'{{"t√™n_c·ªôt_1": "gi√°_tr·ªã", "t√™n_c·ªôt_2": ["gi√°_tr·ªã_1", "gi√°_tr·ªã_2"]}}'`
    - V√≠ d·ª•: ƒê·ªÉ l·ªçc d·ªØ li·ªáu 'ƒê·ªãa ph∆∞∆°ng - Ti·ªÉu h·ªçc' ch·ªâ cho 'H√† N·ªôi' nƒÉm 2021, d√πng: `filters_json='{{"ƒê·ªãa ph∆∞∆°ng": "H√† N·ªôi", "NƒÉm": 2021}}'`
    - V√≠ d·ª•: ƒê·ªÉ l·ªçc cho 'H√† N·ªôi' v√† 'TP. H·ªì Ch√≠ Minh', d√πng: `filters_json='{{"ƒê·ªãa ph∆∞∆°ng": ["H√† N·ªôi", "TP. H·ªì Ch√≠ Minh"]}}'`
    - Khi l·ªçc theo 'ƒê·ªãa ph∆∞∆°ng', h√£y s·ª≠ d·ª•ng t√™n ch√≠nh x√°c t·ª´ danh s√°ch ƒë∆∞·ª£c cung c·∫•p ·ªü tr√™n.
    - N·∫øu kh√¥ng c·∫ßn l·ªçc, b·ªè qua tham s·ªë `filters_json` ho·∫∑c ƒë·∫∑t l√† `None`.
- Khi g·ªçi m·ªôt h√†m c√¥ng c·ª• (v√≠ d·ª•: `generate_histogram`), **b·∫°n B·∫ÆT BU·ªòC ph·∫£i cung c·∫•p tham s·ªë `dataframe_name`** v·ªõi t√™n ch√≠nh x√°c c·ªßa b·ªô d·ªØ li·ªáu b·∫°n ƒë√£ ch·ªçn t·ª´ danh s√°ch tr√™n.
- ƒê·∫£m b·∫£o b·∫°n s·ª≠ d·ª•ng t√™n c·ªôt CH√çNH X√ÅC nh∆∞ ƒë∆∞·ª£c li·ªát k√™ cho b·ªô d·ªØ li·ªáu ƒë√£ ch·ªçn, ch√∫ √Ω ƒë·∫øn ki·ªÉu d·ªØ li·ªáu c·ªßa c·ªôt khi ch·ªçn c√¥ng c·ª• ph√π h·ª£p. Kh√¥ng t·ª± t·∫°o t√™n c·ªôt.
- **ƒê·ªëi v·ªõi `generate_line_chart`:**
    - N·∫øu ng∆∞·ªùi d√πng mu·ªën xem xu h∆∞·ªõng cho c√°c nh√≥m kh√°c nhau (v√≠ d·ª•: xu h∆∞·ªõng h·ªçc sinh theo t·ª´ng ƒë·ªãa ph∆∞∆°ng), h√£y s·ª≠ d·ª•ng tham s·ªë `group_by_column` v·ªõi t√™n c·ªôt ch·ª©a nh√≥m ƒë√≥ (v√≠ d·ª•: 'ƒê·ªãa ph∆∞∆°ng'). √Åp d·ª•ng `filters_json` n·∫øu c·∫ßn l·ªçc th√™m c√°c nh√≥m n√†y.
    - N·∫øu ng∆∞·ªùi d√πng mu·ªën xem xu h∆∞·ªõng t·ªïng th·ªÉ v√† c·ªôt X (v√≠ d·ª•: 'NƒÉm') c√≥ th·ªÉ c√≥ nhi·ªÅu gi√° tr·ªã Y cho m·ªói X (v√≠ d·ª•: nhi·ªÅu ƒë·ªãa ph∆∞∆°ng trong m·ªôt nƒÉm), v√† b·∫°n *kh√¥ng* s·ª≠ d·ª•ng `group_by_column`, h√£y xem x√©t s·ª≠ d·ª•ng tham s·ªë `aggregation`. M·∫∑c ƒë·ªãnh l√† 'sum', nh∆∞ng b·∫°n c√≥ th·ªÉ ch·ªâ ƒë·ªãnh 'mean' ho·∫∑c 'median' n·∫øu ph√π h·ª£p h∆°n v·ªõi y√™u c·∫ßu (v√≠ d·ª•: 'xu h∆∞·ªõng trung b√¨nh s·ªë h·ªçc sinh qua c√°c nƒÉm'). √Åp d·ª•ng `filters_json` n·∫øu c·∫ßn l·ªçc d·ªØ li·ªáu tr∆∞·ªõc khi t·ªïng h·ª£p.
    - N·∫øu c·ªôt X l√† duy nh·∫•t ho·∫∑c b·∫°n ƒëang s·ª≠ d·ª•ng `group_by_column`, b·∫°n kh√¥ng c·∫ßn ch·ªâ ƒë·ªãnh `aggregation`.
- N·∫øu y√™u c·∫ßu y√™u c·∫ßu m·ªôt c·ªôt kh√¥ng t·ªìn t·∫°i trong b·ªô d·ªØ li·ªáu ƒë√£ ch·ªçn, ho·∫∑c s·ª≠ d·ª•ng m·ªôt c·ªôt sai lo·∫°i cho bi·ªÉu ƒë·ªì ƒë∆∞·ª£c y√™u c·∫ßu, h√£y th√¥ng b√°o l·ªói cho ng∆∞·ªùi d√πng.
- ƒê·ªëi v·ªõi c√°c c√¢u h·ªèi chung v·ªÅ d·ªØ li·ªáu (v√≠ d·ª•: 'Gi√° tr·ªã trung b√¨nh trong [c·ªôt] c·ªßa [b·ªô d·ªØ li·ªáu] l√† g√¨?'), h√£y cung c·∫•p c√¢u tr·∫£ l·ªùi tr·ª±c ti·∫øp b·∫±ng vƒÉn b·∫£n d·ª±a tr√™n th√¥ng tin c√≥ s·∫µn (bao g·ªìm f5r). H√£y n√™u r√µ b·∫°n ƒëang ph√¢n t√≠ch b·ªô d·ªØ li·ªáu n√†o v√† c√≥ √°p d·ª•ng b·ªô l·ªçc n√†o kh√¥ng.
- Gi·ªØ c√°c c√¢u tr·∫£ l·ªùi vƒÉn b·∫£n c·ªßa b·∫°n ng·∫Øn g·ªçn v√† t·∫≠p trung v√†o truy v·∫•n c·ªßa ng∆∞·ªùi d√πng.
- N·∫øu ng∆∞·ªùi d√πng y√™u c·∫ßu b·∫°n v·∫Ω m·ªôt bi·ªÉu ƒë·ªì ng·∫´u nhi√™n, h√£y ch·ªçn m·ªôt b·ªô d·ªØ li·ªáu v√† lo·∫°i bi·ªÉu ƒë·ªì ph√π h·ª£p d·ª±a tr√™n c·∫•u tr√∫c d·ªØ li·ªáu (ki·ªÉu c·ªôt, f5r), n√™u r√µ l·ª±a ch·ªçn c·ªßa b·∫°n v√† g·ªçi h√†m c√¥ng c·ª• v·ªõi `dataframe_name` ch√≠nh x√°c.
- **Lu√¥n tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát.**
"""

    user_query = st.chat_input(
        f"H·ªèi v·ªÅ d·ªØ li·ªáu gi√°o d·ª•c...", key="ai_query_input_final"
    )

    chat_msg = None
    if user_query:
        st.session_state["last_call_info"] = None

        st.session_state.chat_history.append(
            types.Content(role="user", parts=[types.Part(text=user_query)])
        )
        with st.chat_message("user"):
            st.markdown(user_query)

        api_history = []
        for msg in st.session_state.chat_history:
            if isinstance(msg, dict):
                role = msg.get("role")
                parts_data = msg.get("parts")
                if role and parts_data:
                    if isinstance(parts_data, list) and isinstance(parts_data[0], str):
                        api_history.append(
                            types.Content(
                                role=role, parts=[types.Part(text=parts_data[0])]
                            )
                        )
            elif isinstance(msg, types.Content):
                api_history.append(msg)

        try:
            with st.spinner("ü§ñ AI ƒëang suy nghƒ©..."):
                response = client.models.generate_content(
                    model="gemini-2.0-flash",
                    contents=api_history,
                    config=types.GenerateContentConfig(
                        tools=[tools],
                        system_instruction=SYSTEM_PROMPT,
                    ),
                )

                response_content = response.candidates[0].content
                st.session_state.chat_history.append(response_content)

                chat_msg = st.chat_message("ai")

                response_part = response_content.parts[0]

                if response_part.function_call:
                    function_call = response_part.function_call
                    function_name = function_call.name
                    function_args = {
                        key: value for key, value in function_call.args.items()
                    }

                    # st.markdown(
                    #     f"_AI mu·ªën ch·∫°y `{function_name}` v·ªõi c√°c tham s·ªë: `{function_args}`_"
                    # )

                    dataframe_name = function_args.get("dataframe_name")
                    if not dataframe_name:
                        chat_msg.error(
                            "L·ªói: AI kh√¥ng ch·ªâ ƒë·ªãnh `dataframe_name` ƒë·ªÉ s·ª≠ d·ª•ng."
                        )
                    elif dataframe_name not in flat_dfs:
                        chat_msg.error(
                            f"L·ªói: AI y√™u c·∫ßu m·ªôt b·ªô d·ªØ li·ªáu kh√¥ng t·ªìn t·∫°i: '{dataframe_name}'. C√°c b·ªô d·ªØ li·ªáu c√≥ s·∫µn: {list(flat_dfs.keys())}"
                        )
                    elif function_name in AVAILABLE_FUNCTIONS:
                        df_to_analyze = flat_dfs[dataframe_name]
                        chart_function = AVAILABLE_FUNCTIONS[function_name]

                        plot_function_args = function_args.copy()
                        del plot_function_args["dataframe_name"]

                        function_args_with_df = {
                            "df": df_to_analyze,
                            **plot_function_args,
                        }

                        required_cols = []
                        if "column_name" in plot_function_args:
                            required_cols.append(plot_function_args["column_name"])
                        if "x_column" in plot_function_args:
                            required_cols.append(plot_function_args["x_column"])
                        if "y_column" in plot_function_args:
                            required_cols.append(plot_function_args["y_column"])
                        if (
                            "group_by_column" in plot_function_args
                            and plot_function_args["group_by_column"]
                            and plot_function_args["group_by_column"] != "None"
                        ):
                            required_cols.append(plot_function_args["group_by_column"])

                        missing_cols = [
                            col
                            for col in required_cols
                            if col not in df_to_analyze.columns
                        ]

                        if missing_cols:
                            chat_msg.error(
                                f"L·ªói: AI y√™u c·∫ßu s·ª≠ d·ª•ng c·ªôt kh√¥ng t·ªìn t·∫°i ({', '.join(missing_cols)}) trong b·ªô d·ªØ li·ªáu '{dataframe_name}'. C√°c c·ªôt c√≥ s·∫µn: {df_to_analyze.columns.tolist()}"
                            )
                        else:
                            # fig = chart_function(**function_args_with_df)

                            # if fig:
                            # hi·ªán chart
                            # st.plotly_chart(fig, use_container_width=True)
                            # l∆∞u fig v√† th√¥ng tin ƒë·ªÉ ph√¢n t√≠ch
                            # st.session_state["last_fig"] = function_args_with_df
                            st.session_state["last_call_info"] = dict(
                                # chart_function=function_name,
                                chart_args=plot_function_args,
                                function_name=function_name,
                                function_args=function_args,
                                dataframe_name=dataframe_name,
                                user_query=user_query,
                            )
                            st.session_state["need_layout"] = False
                            st.rerun()

                            # st.session_state["need_layout"] = False
                            # st.session_state.pop("chart_analysis_result", None)
                            # st.markdown(
                            #     f"OK. ƒê√¢y l√† `{function_name.replace('_', ' ')}` b·∫°n y√™u c·∫ßu cho b·ªô d·ªØ li·ªáu '{dataframe_name}'."
                            # )
                        # else:
                        #     error_message = f"Kh√¥ng th·ªÉ t·∫°o bi·ªÉu ƒë·ªì ƒë∆∞·ª£c y√™u c·∫ßu (`{function_name}`) cho b·ªô d·ªØ li·ªáu '{dataframe_name}'. Vui l√≤ng ki·ªÉm tra l·∫°i y√™u c·∫ßu ho·∫∑c c√°c th√¥ng b√°o l·ªói b√™n tr√™n."
                        #     chat_msg.error(error_message)
                    else:
                        error_message = (
                            f"L·ªói: AI y√™u c·∫ßu m·ªôt h√†m kh√¥ng x√°c ƒë·ªãnh '{function_name}'."
                        )
                        chat_msg.error(error_message)

                elif response_part.text:
                    response_text = response_part.text
                    chat_msg.markdown(response_text)
                else:
                    chat_msg.warning("AI tr·∫£ v·ªÅ m·ªôt ph·∫£n h·ªìi tr·ªëng.")

        except Exception as e:
            st.error(f"ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh t∆∞∆°ng t√°c v·ªõi AI: {e}", icon="üî•")

    # After chat and chart rendering, add analyze button + result
    if (
        "last_call_info" in st.session_state
        and st.session_state["last_call_info"] is not None
    ):
        # Always show the chart before the button and analysis result
        sleep(1)  # Optional: Add a small delay for better UX

        info = st.session_state["last_call_info"]

        # if st.session_state["need_layout"] == True:
        userMsg = st.chat_message("user")
        userMsg.markdown(info["user_query"])

        # st.session_state["need_layout"] = True

        with st.chat_message("ai"):
            st.markdown(
                f"_AI mu·ªën ch·∫°y `{info["function_name"]}` v·ªõi c√°c tham s·ªë: `{info["function_args"]}`_"
            )

            fig = AVAILABLE_FUNCTIONS[info["function_name"]](
                flat_dfs[info["dataframe_name"]], **info["chart_args"]
            )
            if fig:
                st.plotly_chart(fig, use_container_width=True)

                st.markdown(
                    f"OK. ƒê√¢y l√† bi·ªÉu ƒë·ªì b·∫°n y√™u c·∫ßu s·ª≠ d·ª•ng b·ªô d·ªØ li·ªáu '{info["dataframe_name"]}'."
                )

                if st.button("üîç Ph√¢n t√≠ch"):
                    # fig = st.session_state["last_fig"]
                    # info = st.session_state["last_call_info"]
                    img_bytes = fig.to_image(format="png")
                    with st.spinner("ü§ñ ƒêang ph√¢n t√≠ch bi·ªÉu ƒë·ªì..."):
                        resp = client.models.generate_content(
                            model="gemini-2.0-flash",
                            contents=[
                                types.Content(
                                    role="user",
                                    parts=[
                                        types.Part.from_bytes(
                                            mime_type="image/png", data=img_bytes
                                        )
                                    ],
                                ),
                            ],
                            config=types.GenerateContentConfig(
                                system_instruction=CHART_ANALYSIS_PROMPT.format(
                                    function_name=info["function_name"],
                                    function_args=info["function_args"],
                                    system_prompt=SYSTEM_PROMPT,
                                )
                            ),
                        )
                    result = resp.candidates[0].content.parts[0].text
                    # st.session_state["chart_analysis_result"] = result

                    # if "chart_analysis_result" in st.session_state:
                    st.write("**üìà Ph√¢n t√≠ch bi·ªÉu ƒë·ªì:**")
                    st.markdown(result)
            else:
                error_message = f"Kh√¥ng th·ªÉ t·∫°o bi·ªÉu ƒë·ªì ƒë∆∞·ª£c y√™u c·∫ßu (`{function_name}`) cho b·ªô d·ªØ li·ªáu '{dataframe_name}'. Vui l√≤ng ki·ªÉm tra l·∫°i y√™u c·∫ßu ho·∫∑c c√°c th√¥ng b√°o l·ªói b√™n tr√™n."
                st.error(error_message)

    st.write("---")
    if st.session_state.get("chat_history"):
        if st.button("X√≥a l·ªãch s·ª≠ tr√≤ chuy·ªán", key="ai_clear_history_final"):
            st.session_state["chat_history"] = []
            # st.session_state["last_fig"] = None
            st.session_state["last_call_info"] = None
            st.rerun()

elif not client:
    st.warning("Tr·ª£ l√Ω AI y√™u c·∫ßu c·∫•u h√¨nh API v√† kh√≥a API h·ª£p l·ªá.")
elif not flat_dfs:
    st.error("Kh√¥ng th·ªÉ t·∫£i b·∫•t k·ª≥ b·ªô d·ªØ li·ªáu n√†o. Vui l√≤ng ki·ªÉm tra th∆∞ m·ª•c 'data'.")
